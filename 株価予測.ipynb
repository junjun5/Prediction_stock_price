{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.initializers import orthogonal\n",
    "from keras.initializers import TruncatedNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date          object\n",
      "Open         float64\n",
      "High         float64\n",
      "Low          float64\n",
      "Close        float64\n",
      "Adj Close    float64\n",
      "Volume       float64\n",
      "dtype: object\n",
      "             Date          Open          High           Low         Close  \\\n",
      "9764   2002-06-10  11470.919922  11522.040039  11370.209961  11370.209961   \n",
      "9765   2002-06-11  11390.410156  11514.530273  11390.410156  11449.440430   \n",
      "9766   2002-06-12  11392.320313  11405.290039  11261.929688  11327.059570   \n",
      "9767   2002-06-13  11366.059570  11396.280273  11132.589844  11144.839844   \n",
      "9768   2002-06-14  11121.889648  11127.160156  10911.070313  10920.629883   \n",
      "...           ...           ...           ...           ...           ...   \n",
      "14225  2020-04-16  19311.300781  19362.169922  19154.410156  19290.199219   \n",
      "14226  2020-04-17  19575.849609  19922.070313  19554.699219  19897.259766   \n",
      "14227  2020-04-20  19689.849609  19784.380859  19611.789063  19669.119141   \n",
      "14228  2020-04-21  19479.830078  19529.060547  19193.220703  19280.779297   \n",
      "14229  2020-04-22  19109.179688  19137.949219  18858.250000  19137.949219   \n",
      "\n",
      "          Adj Close    Volume  \n",
      "9764   11370.209961   37900.0  \n",
      "9765   11449.440430   39600.0  \n",
      "9766   11327.059570   42800.0  \n",
      "9767   11144.839844   46500.0  \n",
      "9768   10920.629883  112800.0  \n",
      "...             ...       ...  \n",
      "14225  19290.199219   81400.0  \n",
      "14226  19897.259766   87800.0  \n",
      "14227  19669.119141   65000.0  \n",
      "14228  19280.779297   79400.0  \n",
      "14229  19137.949219   76400.0  \n",
      "\n",
      "[4366 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('x-data.csv')\n",
    "#print(df.iloc[:,:])\n",
    "# nullを含んだ行を削除\n",
    "# https://note.nkmk.me/python-pandas-nan-dropna-fillna/\n",
    "df2 = df.iloc[:,:].dropna(how='any')\n",
    "buff = df2.iloc[:,-1] != 0.0\n",
    "df3 = df2[buff]\n",
    "print(df3.dtypes) \n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9764          NaN\n",
      "9765     0.694408\n",
      "9766    -1.074634\n",
      "9767    -1.621792\n",
      "9768    -2.032295\n",
      "           ...   \n",
      "14225   -1.338273\n",
      "14226    3.098487\n",
      "14227   -1.153217\n",
      "14228   -1.994114\n",
      "14229   -0.743547\n",
      "Name: Close, Length: 4366, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junde\\miniconda3\\envs\\dl4us\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df4 = np.log(df3.iloc[:,4])\n",
    "df5 = (df4.diff())\n",
    "print (df5*100)\n",
    "df3.Close = df5*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date     Close\n",
      "9764   2002-06-10       NaN\n",
      "9765   2002-06-11  0.694408\n",
      "9766   2002-06-12 -1.074634\n",
      "9767   2002-06-13 -1.621792\n",
      "9768   2002-06-14 -2.032295\n",
      "...           ...       ...\n",
      "14225  2020-04-16 -1.338273\n",
      "14226  2020-04-17  3.098487\n",
      "14227  2020-04-20 -1.153217\n",
      "14228  2020-04-21 -1.994114\n",
      "14229  2020-04-22 -0.743547\n",
      "\n",
      "[4366 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = df3.iloc[:,[0,4]]\n",
    "label_df = buf.drop(9764)\n",
    "print(train_df)\n",
    "date_df = train_df.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_1_plus = train_df.Close > math.log(1.01)*100\n",
    "less_1_plus = (train_df.Close < math.log(1.01) * 100)&(train_df.Close > math.log(1.00) * 100)\n",
    "less_1_minus = (train_df.Close < math.log(1.00)*100) & (train_df.Close > math.log(0.99)* 100 )\n",
    "more_1_minus = train_df.Close < math.log(0.99) * 100\n",
    "\n",
    "'''\n",
    "more_1_plus = more_1_plus.index.rename('x>1')\n",
    "less_1_plus = less_1_plus.index.rename('0<=x<1')\n",
    "less_1_minus = less_1_minus.index.rename('-1<x<0')\n",
    "more_1_minus = more_1_minus.index.rename('x<-1')\n",
    "'''\n",
    "\n",
    "more_1_plus = more_1_plus*1\n",
    "less_1_plus = less_1_plus*1\n",
    "less_1_minus = less_1_minus*1\n",
    "more_1_minus = more_1_minus*1\n",
    "\n",
    "\n",
    "##print(more_1_plus*1)\n",
    "##print(less_1_plus)\n",
    "##print(less_1_minus)\n",
    "##print(more_1_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = pd.concat([date_df,more_1_plus], axis=1)\n",
    "buf = pd.concat([buf,less_1_plus], axis=1)\n",
    "buf = pd.concat([buf, less_1_minus], axis=1)\n",
    "buf = pd.concat([buf, more_1_minus], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'more_1_plus', 'less_1_plus', 'less_1_minus', 'more_1_minus'], dtype='object')\n",
      "             Date  more_1_plus  less_1_plus  less_1_minus  more_1_minus\n",
      "9764   2002-06-10            0            0             0             0\n",
      "9765   2002-06-11            0            1             0             0\n",
      "9766   2002-06-12            0            0             0             1\n",
      "9767   2002-06-13            0            0             0             1\n",
      "9768   2002-06-14            0            0             0             1\n",
      "...           ...          ...          ...           ...           ...\n",
      "14225  2020-04-16            0            0             0             1\n",
      "14226  2020-04-17            1            0             0             0\n",
      "14227  2020-04-20            0            0             0             1\n",
      "14228  2020-04-21            0            0             0             1\n",
      "14229  2020-04-22            0            0             1             0\n",
      "\n",
      "[4366 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "buf.columns = ['Date','more_1_plus','less_1_plus','less_1_minus','more_1_minus']\n",
    "print(buf.columns)\n",
    "print(buf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(9764)\n",
    "label_df = buf.drop(9764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date     Close\n",
      "9765   2002-06-11  0.694408\n",
      "9766   2002-06-12 -1.074634\n",
      "9767   2002-06-13 -1.621792\n",
      "9768   2002-06-14 -2.032295\n",
      "9769   2002-06-17 -2.376972\n",
      "...           ...       ...\n",
      "14225  2020-04-16 -1.338273\n",
      "14226  2020-04-17  3.098487\n",
      "14227  2020-04-20 -1.153217\n",
      "14228  2020-04-21 -1.994114\n",
      "14229  2020-04-22 -0.743547\n",
      "\n",
      "[4365 rows x 2 columns]\n",
      "             Date  more_1_plus  less_1_plus  less_1_minus  more_1_minus\n",
      "9765   2002-06-11            0            1             0             0\n",
      "9766   2002-06-12            0            0             0             1\n",
      "9767   2002-06-13            0            0             0             1\n",
      "9768   2002-06-14            0            0             0             1\n",
      "9769   2002-06-17            0            0             0             1\n",
      "...           ...          ...          ...           ...           ...\n",
      "14225  2020-04-16            0            0             0             1\n",
      "14226  2020-04-17            1            0             0             0\n",
      "14227  2020-04-20            0            0             0             1\n",
      "14228  2020-04-21            0            0             0             1\n",
      "14229  2020-04-22            0            0             1             0\n",
      "\n",
      "[4365 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)\n",
    "print(label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\")\n",
    "label_df.to_csv(\"label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape= (4365, 1)\n"
     ]
    }
   ],
   "source": [
    "df1 = csv.reader(open('train.csv', 'r'))\n",
    "data1 = [ v for v in df1]\n",
    "mat = np.array(data1)\n",
    "mat2 = mat[1:]                        # 見出し行を外す\n",
    "x_data = mat2[:, 2:].astype(np.float)  # 2列目以降を抜き出してfloat変換\n",
    "print('x_data.shape=', x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_data.shape= (4365, 4)\n"
     ]
    }
   ],
   "source": [
    "df2 = csv.reader(open('label.csv', 'r'))\n",
    "data2 = [ v for v in df2]\n",
    "mat3 = np.array(data2)\n",
    "mat4 = mat3[1:]                       # 見出し行を外す\n",
    "t_data = mat4[:, 2:].astype(np.float)  # 2列目以降を抜き出してfloat変換\n",
    "print('t_data.shape=', t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4286, 80, 1) (4286, 4)\n",
      "(3857, 80, 1) (429, 80, 1) (3857, 4) (429, 4)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 80              # 入力系列数\n",
    "n_in = x_data.shape[1]   # 学習データ（＝入力）の列数\n",
    "n_out = t_data.shape[1]  # ラベルデータ（=出力）の列数\n",
    "len_seq = x_data.shape[0] - maxlen + 1\n",
    "data = []\n",
    "target = []\n",
    "for i in range(0, len_seq):\n",
    "  data.append(x_data[i:i+maxlen, :])\n",
    "  target.append(t_data[i+maxlen-1, :])\n",
    "\n",
    "x = np.array(data).reshape(len(data), maxlen, n_in)\n",
    "t = np.array(target).reshape(len(data), n_out)\n",
    "\n",
    "print(x.shape, t.shape)\n",
    "\n",
    "# ここからソースコードの後半\n",
    "n_train = int(len(data)*0.9)              # 訓練データ長\n",
    "x_train,x_test = np.vsplit(x, [n_train])  # 学習データを訓練用とテスト用に分割\n",
    "t_train,t_test = np.vsplit(t, [n_train])  # ラベルデータを訓練用とテスト用に分割\n",
    "\n",
    "print(x_train.shape, x_test.shape, t_train.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4286\n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(t_data[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "  def __init__(self, maxlen, n_hidden, n_in, n_out):\n",
    "    self.maxlen = maxlen\n",
    "    self.n_hidden = n_hidden\n",
    "    self.n_in = n_in\n",
    "    self.n_out = n_out\n",
    "\n",
    "  def create_model(self):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(self.n_hidden, batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "             kernel_initializer = glorot_uniform(seed=20170719), \n",
    "             recurrent_initializer = orthogonal(gain=1.0, seed=20170719), \n",
    "             dropout = 0.5, \n",
    "             recurrent_dropout = 0.5))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(self.n_out, \n",
    "            kernel_initializer = glorot_uniform(seed=20170719)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer = \"RMSprop\", metrics = ['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "  # 学習\n",
    "  def train(self, x_train, t_train, batch_size, epochs) :\n",
    "    early_stopping = EarlyStopping(patience=0, verbose=1)\n",
    "    model = self.create_model()\n",
    "    model.fit(x_train, t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "          shuffle = True, callbacks = [early_stopping], validation_split = 0.1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3471 samples, validate on 386 samples\n",
      "Epoch 1/100\n",
      "3471/3471 [==============================] - 8s 2ms/step - loss: 1.2269 - categorical_accuracy: 0.4180 - val_loss: 1.0418 - val_categorical_accuracy: 0.7720\n",
      "Epoch 2/100\n",
      "3471/3471 [==============================] - 8s 2ms/step - loss: 1.0594 - categorical_accuracy: 0.5076 - val_loss: 0.8801 - val_categorical_accuracy: 0.8627\n",
      "Epoch 3/100\n",
      "3471/3471 [==============================] - 8s 2ms/step - loss: 0.9582 - categorical_accuracy: 0.5494 - val_loss: 0.7120 - val_categorical_accuracy: 0.8212\n",
      "Epoch 4/100\n",
      "3471/3471 [==============================] - 9s 2ms/step - loss: 0.9168 - categorical_accuracy: 0.5667 - val_loss: 0.6784 - val_categorical_accuracy: 0.8264\n",
      "Epoch 5/100\n",
      "3471/3471 [==============================] - 8s 2ms/step - loss: 0.8803 - categorical_accuracy: 0.5733 - val_loss: 0.5781 - val_categorical_accuracy: 0.8135\n",
      "Epoch 6/100\n",
      "3471/3471 [==============================] - 9s 2ms/step - loss: 0.8486 - categorical_accuracy: 0.5860 - val_loss: 0.5403 - val_categorical_accuracy: 0.7772\n",
      "Epoch 7/100\n",
      "3471/3471 [==============================] - 8s 2ms/step - loss: 0.8328 - categorical_accuracy: 0.5872 - val_loss: 0.4983 - val_categorical_accuracy: 0.8083\n",
      "Epoch 8/100\n",
      "3471/3471 [==============================] - 8s 2ms/step - loss: 0.8358 - categorical_accuracy: 0.5918 - val_loss: 0.4513 - val_categorical_accuracy: 0.8238\n",
      "Epoch 9/100\n",
      "3471/3471 [==============================] - 9s 2ms/step - loss: 0.7994 - categorical_accuracy: 0.6108 - val_loss: 0.5150 - val_categorical_accuracy: 0.7927\n",
      "Epoch 00009: early stopping\n",
      "429/429 [==============================] - 0s 512us/step\n",
      "score: [0.5287730187559739, 0.8228438496589661]\n",
      "正答率: 0.8228438228438228\n",
      "準正答率（騰落）: 0.9906759906759907\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 80     # 出力次元\n",
    "epochs = 100      # エポック数\n",
    "batch_size = 10   # ミニバッチサイズ\n",
    "\n",
    "# モデル定義\n",
    "prediction = Prediction(maxlen, n_hidden, n_in, n_out)\n",
    "# 学習\n",
    "model = prediction.train(x_train, t_train, batch_size, epochs)\n",
    "# テスト\n",
    "score = model.evaluate(x_test, t_test, batch_size = batch_size, verbose = 1)\n",
    "print(\"score:\", score)\n",
    "\n",
    "# 正答率、準正答率（騰落）集計\n",
    "preds = model.predict(x_test)\n",
    "correct = 0\n",
    "semi_correct = 0\n",
    "for i in range(len(preds)):\n",
    "  pred = np.argmax(preds[i,:])\n",
    "  tar = np.argmax(t_test[i,:])\n",
    "  if pred == tar :\n",
    "    correct += 1\n",
    "  else :\n",
    "    if pred+tar == 1 or pred+tar == 5 :\n",
    "      semi_correct += 1\n",
    "\n",
    "print(\"正答率:\", 1.0 * correct / len(preds))\n",
    "print(\"準正答率（騰落）:\", 1.0 * (correct+semi_correct) / len(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
